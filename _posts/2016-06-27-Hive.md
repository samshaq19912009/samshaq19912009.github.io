---
layout: post
title: Mac上配置Hive指南
date: 2016-06-28
categories: blog
tags: [Hive]
description: Hive
---

今天纠结了一下午的Hive。到处找资料配置，还是把自己的坑列出来，希望对别人有用吧。。


首先，安装hive之前需要安装Hadoop。这个就不多说了。反正在Mac上都是无脑的brew install。。。。然后再bash_profile里面加入path。。。


值得注意的是，运行hive**需要Hadoop已经运行了！**。这个就已经坑了我半个小时。。插一句，Hadoop的运行命令为**hstart**。另外可以用**jps**来检查Hadoop的运行情况。

### 第一步

粗暴简单，你懂得。（如果你还没装brew，请出门左拐装完homebrew再回来）

```bash
brew install hive
```

### 第二步， 配置文件

配置bash profile,这里的hadoop.version.no和hive.version.no都是版本号，我的是2.7.2和2.0

```bash
emacs ~/.bash_profile

export HADOOP_HOME=/usr/local/Cellar/hadoop/hadoop.version.no
export HIVE_HOME=/usr/local/Cellar/hive/hive.version.no/libexec
source ~/.bash_profile

```

### 第三步 创建HDFS文件

```bash
hdfs dfs -mkdir /user/hive/warehouse
hdfs dfs -mkdir -p /user/hive/warehouse
hdfs dfs -chmod g+w /tmp
hdfs dfs -chmod g+w /user/hive/warehouse

```

### 配置 hive-site.xml 和 hcat.out

这个hive-site.xml非常重要，在我的系统里，这个文件在**/usr/local/Cellar/hive/2.0.1/libexec/conf**，就把下面的代码放入即可，不要手贱乱配置。

```
<configuration>
 <property>
  <name>hive.exec.scratchdir</name>
  <value>/tmp/hive-${user.name}</value>
  <description>Scratch space for Hive jobs</description>
 </property>
</configuration>


```


hcat.out这个我也不知道有啥用。。。反正就配置吧。。。


```
mkdir -p hcatalog/var/log
touch hcatalog/var/log/hcat.out

```

#### 配置hive的path

最后在你的bash_profile里面加入hive的path。。。。

```

export HIVE_HOME=/usr/local/Cellar/hive/2.0.1/libexec

export PATH=/usr/local/Cellar/hive/2.0.1/bin:$PATH

```

### 第四步 运行吧！少年！

如果一切正常的话，就可以运行了！！！！

输入

```
hive

```

就可以看到进入了hive的界面。

如果提示不成功，提示为**Hive installation issues: Hive metastore database is not initialized**，可以参考如下[post](http://stackoverflow.com/questions/35655306/hive-installation-issues-hive-metastore-database-is-not-initialized)

```
schematool -initSchema -dbType derby

# 如果以上命令不成功，就先run下面这个
mv metastore_db metastore_db.tmp

# run完上面那个，再run
schematool -initSchema -dbType derby


# 最后再尝试hive

hive
```

### 第五步 例子


```
hive> CREATE TABLE pokes (foo INT, bar STRING);
> OK
> Time taken: 0.098 seconds
hive> CREATE TABLE invites (foo INT, bar STRING) PARTITIONED BY (ds STRING);
> OK
> Time taken: 0.077 seconds
hive> SHOW TABLES;
> OK
> invites
> pokes
> u_data
> Time taken: 0.093 seconds, Fetched: 3 row(s)

hive> SHOW TABLES '.*s';

> OK
> invites
> pokes
> Time taken: 0.034 seconds, Fetched: 2 row(s)

hive> DESCRIBE invites;

> OK

> foo int
> bar string
> ds string
>

> # Partition Information
> # col_name data_type comment
>
> ds string

> Time taken: 0.08 seconds, Fetched: 8 row(s)


```


### 第六步 还是一个例子


另外，也可以从local data中导入数据，具体代码如下

```
# 先下载数据
wget http://files.grouplens.org/datasets/movielens/ml–100k.zip
unzip ml–100k.zip


#再在hive里面录入


hive> CREATE TABLE u_data (
  userid INT,
  movieid INT,
  rating INT,
  unixtime STRING)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY '\t'
STORED AS TEXTFILE;

hive> LOAD DATA LOCAL INPATH '../ml–100k/u.data' OVERWRITE INTO TABLE u_data;

> Loading data to table default.u_data
> Table default.u_data stats: [numFiles=1, numRows=0, totalSize=1979173, rawDataSize=0]
> OK
> Time taken: 0.498 seconds

hive> SELECT COUNT(*) FROM u_data;

> Query ID = marekbejda_20150329143434_59ae5f17-bb06–4a6e-a029–4a03da1a4be0
> Total jobs = 1
> Launching Job 1 out of 1
> Number of reduce tasks determined at compile time:

> In order to change the average load for a reducer (in bytes):
set hive.exec.reducers.bytes.per.reducer=number

> In order to limit the maximum number of reducers:
set hive.exec.reducers.max=number

> In order to set a constant number of reducers:
set mapreduce.job.reduces=number

> Job running in-process (local Hadoop)
> 2015–03–29 14:34:55,170 Stage–1 map = 100%, reduce = 100
> Ended Job = job_local1972666714_0001

> MapReduce Jobs Launched:
> Stage-Stage–1: HDFS Read: 3958346 HDFS Write: 3958346 SUCCESS
> Total MapReduce CPU Time Spent: 0 msec
> OK
> 100000
> Time taken: 2.228 seconds, Fetched: 1 row(s)

```

遗憾的是到这一步我一直不成功，具体报错为**Failed with exception Unable to move source file:/Users/Sakamoto/Downloads/ml-100k/u.data to destination hdfs://localhost:9000/user/hive/warehouse/u_data/u.data**

**FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.MoveTask**

谷歌了很久也不知道为啥。就酱紫吧


本文参考链接为

[一个人写的博客](https://amodernstory.com/2015/03/29/installing-hive-on-mac/comment-page-1/#comment-1553)


[官方文档](https://cwiki.apache.org/confluence/display/Hive/GettingStarted#GettingStarted-InstallationandConfiguration)

[另一个人写的博客](https://noobergeek.wordpress.com/2013/11/09/simplest-way-to-install-and-configure-hive-for-mac-osx-lion/)

[Hive 简要操作指南](http://mp.weixin.qq.com/s?__biz=MzIzODExMDE5MA==&mid=2694182433&idx=1&sn=687b754cddc7255026434c683f487ac0#rd)

