---
layout: post
title: LDA 简介
date: 2016-06-23
categories: blog
tags: [Machine Learning,LDA]
description: LDA
---



# LDA 简介

我们来学习一下LDA（Latent Dirichlet Allocation）模型。

## 前言

按照wiki上的介绍，LDA由Blei, David M.、Ng, Andrew Y.、Jordan于2003年提出，是一种[主题模型](https://zh.wikipedia.org/wiki/主题模型)，它可以将文档集 中每篇文档的主题以概率分布的形式给出，从而通过分析一些文档抽取出它们的主题（分布）出来后，便可以根据主题（分布）进行主题聚类或文本分类。同时，它是一种典型的词袋模型，即一篇文档是由一组词构成，词与词之间没有先后顺序的关系。

一篇文档可以包含多个主题，文档中每一个词都由其中的一个主题生成。当人们需要生成一段文档的时候，首先确定假定这一段文档所包含的topic，而每一个topic都有包含的词汇。如下图所示，包含四个话题。
![model](http://img.blog.csdn.net/20141117153816148)

生成文档时，以一定的概率选取上述某个主题，再以一定的概率选取那个主题下的某个单词，不断的重复这两步，最终生成如下图所示的一篇文章

![test](http://img.blog.csdn.net/20141117154035285)

反之，在训练阶段，我们需要反推这一个过程，推断这一段文章是由什么主题组成的。假定们可能会认为作者先确定这篇文章的几个主题，然后围绕这几个主题遣词造句，表达成文。
    
LDA就是要干这事：根据给定的一篇文档，推测其主题分布。通过此模型生成的文档方式如下：

1.从狄利克雷分布$\alpha$中取样生成文档 i 的主题分布$\theta_i$

2.从主题的多项式分布$\theta_i$中取样生成文档i第 j 个词的主题$z_{ij}$

3.从狄利克雷分布$\beta$中取样生成主题对应的词语分布$\phi_{z_{ij}}$

4.从词语的多项式分布中采样最终生成词语$w_{ij}$



![dict](http://img.blog.csdn.net/20141117152903751)


#### 二项分布（Binomial distribution）

二项分布是从伯努利分布推进的。伯努利分布，又称两点分布或0-1分布，是一个离散型的随机分布，其中的随机变量只有两类取值，非正即负{+，-}。而二项分布即重复n次的伯努利。简言之，只做一次实验，是伯努利分布，重复做了n次，是二项分布。二项分布的概率密度函数为

![bi](http://img.blog.csdn.net/20141117234739906)


#### 多项分布（Multinomial Distribution）

多项分布是指单次试验中的随机变量的取值不再是0-1的，而是有多种离散值可（1,2,3...,k）。比如投掷6个面的骰子实验，N次实验结果服从K=6的多项分布。其中

![pro](http://img.blog.csdn.net/20141117235427677)

多项分布的概率密度函数为：

![mulit](http://img.blog.csdn.net/20141117235452512)


#### Beta 分布（Beta distribution）

给定参数$\alpha$和$\beta$，取值为[0,1]的随机变量x的概率密度函数为

![beta](http://img.blog.csdn.net/20141117235056953)

其中

![gamma](http://img.blog.csdn.net/20141117235115532),![gamma](http://img.blog.csdn.net/20141117235123035)

注意其中的Gamma函数。

#### Dirichlet 分布（Dirichlet distribution）是beta分布在高维度上的推广

![Dir](http://img.blog.csdn.net/20141117235506350)

其中

![dir1](http://img.blog.csdn.net/20141117235524695)

#### Gamma 函数与 Beta 分布

**问题1**

给定$x_1, x_2, x_n.....$为均匀[0,1]分布的随机变量，将这n的变量随机排序后，$x_k$的分布为？

![gamma](http://img.blog.csdn.net/20141117174509835)


取定$\alpha=k$和$\beta = n-k+1$

![fromgamama](http://img.blog.csdn.net/20141117180513843)


## Beta分布

以上已经介绍过Beta分布的基本数学公式以及概率含义，为了理解 Beta 分布和 二项分布的共轭关系，我们重新回到上面一个问题


**问题2**

给定$x_1, x_2, x_n.....$为均匀[0,1]分布的随机变量，将这n的变量随机排序后，$ p = X_k$

给定$y_1, y_2, y_n.....$为均匀[0,1]分布的随机变量, Y 中有 m1 比 P 小， m2 比 p 大， 

求问p对Y的条件概率？？？

![pY](http://img.blog.csdn.net/20141117183714937)

**先验分布** + **样本信息** = **后验分布**

我们知道，这一问题的先验分布为Beta分布，样本信息为[0,1]二项分布

类比以上问题，我们可以得到以下等式

![x1](http://img.blog.csdn.net/20141117185216670)

更一般的关系为


![con](http://img.blog.csdn.net/20141117185325671)

由此，我们可以得到 **针对于这种观测到的数据符合二项分布，参数的先验分布和后验分布都是Beta分布的情况**，**就是Beta-Binomial共轭**。换言之，Beta分布是二项式分布的共轭先验概率分布

### 共轭先验概率分布


**在贝叶斯概率理论中，如果后验概率和先验概率满足同样的分布律，那么，先验分布和后验分布被叫做共轭分布，同时，先验分布叫做似然函数的共轭先验分布**


举个例子。投掷一个非均匀硬币，可以使用参数为θ的伯努利模型，θ为硬币为正面的概率，那么结果x的分布形式为：

![re](http://img.blog.csdn.net/20141117224140453)


其共轭先验为beta分布，具有两个参数$\alpha$和$\beta$，称为超参数（hyperparameters）。且这两个参数决定了θ参数，其Beta分布形式为

![re](http://img.blog.csdn.net/20141117230028113)

然后计算后验概率为

![re](http://img.blog.csdn.net/20141117230441640)

可以看到，先验假设和后验分布同为Beta分布！

此外，如果变量符合Beta变量，平均值为：

![average](http://img.blog.csdn.net/20141117204010541)

## Dirichlet 分布

### 3.1 Dirichlet 分布

根据wikipedia上的介绍，维度K ≥ 2（x1,x2…xK-1维，共K个）的狄利克雷分布在参数α1, ..., αK > 0上、基于欧几里得空间里的勒贝格测度有个概率密度函数，定义为：

![average](http://img.blog.csdn.net/20141117232638381)


其中

![average](http://img.blog.csdn.net/20141117233352295)


### 3.2 Dirichlet-Multinomial 共轭

下面，在问题2的基础上继续深入，引出**问题3**。

给定$x_1, x_2, x_n.....$为均匀[0,1]分布的随机变量，将这n的变量随机排序后，$x_k$的分布为？以三维变量为例， 这里我们只采用$x1$ $x2$为自由变量， 为了简化计算，取x3满足x1+x2+x3=1,但只有x1,x2是变量，如下图所示


![fig3](http://img.blog.csdn.net/20141117234134290)

从而有：

![fig3](http://img.blog.csdn.net/20141118003458723)

继而我们可以得到联合分布为


![fig3](http://img.blog.csdn.net/20141118003624156)


观察上述式子的最终结果，可以看出上面这个分布其实就是3维形式的 Dirichlet 分布


![fig3](http://img.blog.csdn.net/20141118003740698)

整理变量后 分布密度可以写为

![fig3](http://img.blog.csdn.net/20141118003817062)


下面，跟问题2比较类似的是，加入观测，

给定$x_1, x_2, x_n.....$为均匀[0,1]分布的随机变量，将这n的变量随机排序后

令$p1=X(k1), p2=X(k2), p3 = 1 - p1 - p2$, 要求$P$的分布

给定$y_1, y_2, y_n.....$为均匀[0,1]分布的随机变量, Y 中有 m1 比 p1 小， m2 在 p1 和 p2 之间， 求问 P 对 y 的条件概率分布？？？

同样，根据Bayes定理，分为三步：

1.先验分布为Dir p1, p2, p3

2.观测为 m1, m2, m3

3.后验分布可以写为以下的形式：

![p](http://img.blog.csdn.net/20141118215146718)

以上过程可以直观的表示为


![p1](http://img.blog.csdn.net/20141118220632031)

可把从整数集合延拓到实数集合，从而得到更一般的表达式如下

![p1](http://img.blog.csdn.net/20141118220737504)



针对于这种观测到的数据符合多项分布，**参数的先验分布和后验分布都是Dirichlet 分布的情况，就是Dirichlet-Multinomial 共轭**。换言之，至此已经证明了Dirichlet分布的确就是多项式分布的共轭先验概率分布。
意味着，如果我们为多项分布的参数p选取的先验分布是Dirichlet分布，那么以p为参数的多项分布用贝叶斯估计得到的后验分布仍然服从Dirichlet分布。

同样，与Beta分布类似， 期望值为

![daver](http://img.blog.csdn.net/20141117211142562)


## 4 主题模型LDA

为了更好的理解LDA的模型，我们先来总结一下学到的知识哈。

**Beta分布是二项式分布的共轭先验概率分布**

对于非负$\alpha$和$\beta$, 我们有如下关系

![p1](http://img.blog.csdn.net/20141117185325671)

针对于这种观测到的数据符合二项分布，参数的先验分布和后验分布都是Beta分布的情况，就是Beta-Binomial 共轭


**狄利克雷分布（Dirichlet分布）是多项式分布的共轭先验概率分布**

把从整数集合延拓到实数集合，从而得到更一般的表达式如下

![p1](http://img.blog.csdn.net/20141118220737504)

针对于这种观测到的数据符合多项分布，参数的先验分布和后验分布都是Dirichlet 分布的情况，就是 Dirichlet-Multinomial 共轭。

以及贝叶斯派思考问题的固定模式

**先验分布** + **样本信息** = **后验分布**

顺便提下频率派与贝叶斯派各自不同的思考方式：

频率派把需要推断的参数θ看做是固定的未知常数，即概率虽然是未知的，但最起码是确定的一个值，同时，样本X 是随机的，所以频率派重点研究样本空间，大部分的概率计算都是针对样本X 的分布；

而贝叶斯派的观点则截然相反，他们认为待估计的参数是随机变量，服从一定的分布，而样本X 是固定的，由于样本是固定的，所以他们重点研究的是参数的分布。


为了方便描述，首先定义一些变量：

w 表示词， V 表示所有单词的个数（固定值）

z 表示主题， k 是主题的个数（预先给定，固定值）

$D = {w1, w2,...., w_{M}}$ 表示语料库，其中的 M 是语料库中的文档数（固定值)

$w = {\omega_1, \omega_2,...., \omega_N}$, 其中的 N 表示一个文档中的词数（随机变量）。

### 4.1 各种基础模型

#### 4.4.1 Unigram model

对于文档$w = {\omega_1, \omega_2,...., \omega_N}$， 用$p(\omega_n)$表示词汇 $\omega_n$ 的先验概率，生成文档$w_n$的概率为

![p1](http://img.blog.csdn.net/20141118233228339)

其图模型为（图中被涂色的w表示可观测变量，N表示一篇文档中总共N个单词，M表示M篇文档）：

![p1](http://img.blog.csdn.net/20141118233121976)

或者


![p1](http://img.blog.csdn.net/20141118234545921)


unigram model假设文本中的词服从Multinomial分布，而我们已经知道Multinomial分布的先验分布为Dirichlet分布。


一般α由经验事先给定，p由观察到的文本中出现的词学习得到，表示文本中出现每个词的概率。




